{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to data science\n",
    "Author: Gérard Lichtert\n",
    "\n",
    "## Introduction\n",
    "This notebook is to clean data from a csv, it removes unnecesary columns, computes means and saves the processed data to a new csv file found in the output folder.\n",
    "\n",
    "It will also make a new dataframe containing averages per day per participant and save it to a csv for the OBSE survey\n",
    "\n",
    "## Usage\n",
    "Following the instructions in the README.md file is crucial for installation. Prior to execution make sure to have that the CSV files are correctly structured. By this I mean that sometimes a CSV file can have unexpected quotation marks between columns, making it one big column. The easiest thing you can do, only if there are no column names containing a comma is to use CTRL+F to find all the quotation characters and replacing them by nothing (or an empty space). You might find the replace-all function beneficial for this. \n",
    "\n",
    "Currently the notebook works under the assumption that you have \"\\<no-response\\>\" in your dataset. This causes all columns that have this value to be interprested as strings. The program will clean these and cast the columns to integers. You might have to adapt the program if it contains null values instead of \"\\<no-response\\>\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables you can change\n",
    "In the following code cells you can change the variables as you need as these will be the columns that need to be removed from the OBSE survey and the other one respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of headers we want to delete (exluding the ones with _TZ, _RT and _TZ) from the OBSE survey\n",
    "# the headers with _TZ, _RT and _TZ will be removed automatically.\n",
    "HEADERS_TO_DROP_FINAL_SURVEY: list[str] = [\n",
    "    \"Start Date\",\n",
    "    \"End Date\",\n",
    "    \"Response Type\",\n",
    "    \"IP Address\",\n",
    "    \"Progress\",\n",
    "    \"Duration (in seconds)\",\n",
    "    \"Finished\",\n",
    "    \"Recorded Date\",\n",
    "    \"Response ID\",\n",
    "    \"Recipient Last Name\",\n",
    "    \"Recipient First Name\",\n",
    "    \"External Data Reference\",\n",
    "    \"Location Latitude\",\n",
    "    \"Location Longitude\",\n",
    "    \"Distribution Channel\",\n",
    "    \"User Language\",\n",
    "    \"Recipient Email\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of headers we want to delete (exluding the ones with _TZ, _RT and _TZ) from the afvar survey\n",
    "# the headers with _TZ, _RT and _TZ will be removed automatically.\n",
    "HEADERS_TO_DROP_SEMA_AND_OBSE = [\n",
    "    \"STUDY_ID\",\n",
    "    \"STUDY_NAME\",\n",
    "    \"STUDY_VERSION\",\n",
    "    \"SURVEY_ID\",\n",
    "    \"TRIGGER\",\n",
    "    \"EXPORT_TZ\",\n",
    "    \"START_END\",\n",
    "    \"CREATED_TS\",\n",
    "    \"SCHEDULED_TS\",\n",
    "    \"STARTED_TS\",\n",
    "    \"EXPIRED_TS\",\n",
    "    \"TOTAL_RT\",\n",
    "    \"RAND_PROB\",\n",
    "    \"PARTICIPANT_TZ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS_TO_DROP_FROM_DEMOGRAPHICS: list[str] = [\n",
    "    \"Start Date\",\n",
    "    \"End Date\",\n",
    "    \"Response Type\",\n",
    "    \"IP Address\",\n",
    "    \"Progress\",\n",
    "    \"Duration (in seconds)\",\n",
    "    \"Finished\",\n",
    "    \"Recorded Date\",\n",
    "    \"Response ID\",\n",
    "    \"Recipient Last Name\",\n",
    "    \"Recipient First Name\",\n",
    "    \"Recipient Email\",\n",
    "    \"External Data Reference\",\n",
    "    \"Location Latitude\",\n",
    "    \"Location Longitude\",\n",
    "    \"Distribution Channel\",\n",
    "    \"User Language\",\n",
    "    \"Beste participant,\\r\\n\\r\\nHartelijk dank voor uw deelname aan dit onderzoek.\\r\\n\\r\\n\\r\\n\\r\\nHet onderzoek\\r\\n\\r\\nhet onderzoek bestaat uit twee delen en peilt naar de relatie met uw werk. Deze enquête vormt het eerste deel van het onderzoek. De enquête bevat tien vragen en neemt ongeveer één minuut in beslag. Deze enquête gaat na of u in aanmerking komt voor het tweede deel van het onderzoek betreffende de relatie met uw werk. We vragen uw e-mailadres om u vervolgens een uitnodiging tot de app SEMA3 te sturen. Via deze app zal u het tweede deel van het onderzoek kunnen vervolledigen. \\r\\n\\r\\n\\r\\n\\r\\nProcedure\\r\\n\\r\\nHet onderzoek zelf of het tweede deel betreft een dagboekonderzoek. Hierbij zal u 20 werkdagen lang om 18h een vragenlijst krijgen, waarin u bevraagd zal worden over uw werkdag. Het invullen van deze vragenlijst zal niet langer duren dan 1 minuut. U heeft de tijd tot 24h om deze vragenlijst in te vullen. Participanten die aan 80% of meer meetmomenten deelnamen krijgen een vergoeding voor hun participatie.\\r\\n\\r\\n\\r\\n\\r\\nWat gebeurt er met mijn gegevens?\\r\\n\\r\\nDe verzamelde gegevens worden alleen gebruikt voor wetenschappelijke doeleinden en worden vertrouwelijk behandeld in overeenstemming met de Europese Algemene Verordening Gegevensbescherming (GDPR). Uw deelname is vrijwillig en u kunt op elk moment beslissen om het onderzoek zonder het geven van een reden te beëindigen. Voor meer informatie over uw rechten en de behandeling van de gegevens kunt u contact opnemen met de verantwoordelijke afdeling aan de VUB (dpo@vub.be).\\r\\n\\r\\n\\r\\n\\r\\nContact\\r\\n\\r\\nAls u vragen en/of opmerkingen hebt over dit onderzoek, kunt u ze hieronder meegeven of contact opnemen met Sam de Pape (Sam.De.Pape@vub.be) of Jules Joukes (Jules.Sabine.P.Joukes@vub.be), of met superviserend professor Joeri Hofmans (Joeri.Hofmans@vub.be).\",\n",
    "    \"Door deze enquête in te vullen, ga ik akkoord met mijn deelname aan dit onderzoek en met de verwerking van mijn persoonlijke gegevens in overeenstemming met de Europese Algemene Verordening Gegevensbescherming (GDPR) door de onderzoekers van de VUB.\",\n",
    "    \"Gaat u volgende maand minstens één week op vakantie? - Selected Choice\",\n",
    "    \"Gaat u volgende maand minstens één week op vakantie? - Andere, namelijk: - Text\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSE_COLUMNS = [\n",
    "    \"PARTICIPANT_ID\",\n",
    "    \"UPLOADED_TS\",\n",
    "    \"ACTIVITEIT\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \"10\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some libraries and definitions (do not change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "resources = Path(\"../resources/in/\")\n",
    "out = Path(\"../resources/out/\")\n",
    "\n",
    "\n",
    "def write_csv_and_excel(lf, filename):\n",
    "    lf.sink_csv(f\"{out.as_posix()}/{filename}.csv\")\n",
    "    lf.collect().write_excel(f\"{out.as_posix()}/{filename}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_survey_lf: pl.LazyFrame = pl.scan_csv(f\"{resources.as_posix()}/final_survey.csv\")\n",
    "sema_lf: pl.LazyFrame = pl.scan_csv(\n",
    "    resources.as_posix() + \"/\" + \"data_uit_SEMA3_OBSE_en_laatste_survey.csv\"\n",
    ")\n",
    "demographics_lf: pl.LazyFrame = pl.scan_csv(\n",
    "    resources.as_posix() + \"/\" + \"demografische_gegevens_eerste_survey.csv\"\n",
    ")\n",
    "keys: pl.LazyFrame = pl.scan_csv(\n",
    "    f\"{resources.as_posix()}/identificatie_key.csv\", separator=\";\"\n",
    ")\n",
    "\n",
    "\n",
    "def remove_headers(\n",
    "    lf: pl.LazyFrame, headers: list[str], del_timed_headers=True\n",
    ") -> pl.LazyFrame:\n",
    "    columns: list[str] = lf.columns\n",
    "    keep = [col for col in columns if col not in headers]\n",
    "    if del_timed_headers:\n",
    "        keep = [\n",
    "            col\n",
    "            for col in keep\n",
    "            if not col.endswith(\"_TZ\")\n",
    "            and not col.endswith(\"_RT\")\n",
    "            and not col.endswith(\"_TZ\")\n",
    "        ]\n",
    "    return lf.select(keep)\n",
    "\n",
    "\n",
    "demographics_lf = remove_headers(\n",
    "    demographics_lf, HEADERS_TO_DROP_FROM_DEMOGRAPHICS, False\n",
    ")\n",
    "final_survey_lf = remove_headers(final_survey_lf, HEADERS_TO_DROP_FINAL_SURVEY, False)\n",
    "sema_en_obse_lf = remove_headers(sema_lf, HEADERS_TO_DROP_SEMA_AND_OBSE)\n",
    "obse_lf: pl.LazyFrame = sema_en_obse_lf.filter(pl.col(\"SURVEY_NAME\") == \"OBSE\")\n",
    "sema_lf: pl.LazyFrame = sema_en_obse_lf.filter(\n",
    "    pl.col(\"SURVEY_NAME\") == \"werktevredenheid/ SWLS/ PRESTATIE\"\n",
    ").filter(pl.col(\"UPLOADED_TS\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "obse_lf: pl.LazyFrame = (\n",
    "    obse_lf.select(OBSE_COLUMNS)\n",
    "    .filter(pl.col(\"ACTIVITEIT\") == \"1\")\n",
    "    .cast({str(integer): pl.UInt8 for integer in range(1, 11)})\n",
    ")\n",
    "valid_obse_participants: list[str] = (\n",
    "    obse_lf.group_by(\"PARTICIPANT_ID\")\n",
    "    .len()\n",
    "    .filter(pl.col(\"len\") >= 5)\n",
    "    .select(\"PARTICIPANT_ID\")\n",
    "    .unique()\n",
    "    .collect()\n",
    "    .to_dict(as_series=False)[\"PARTICIPANT_ID\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_survey_lf: pl.LazyFrame = (\n",
    "    final_survey_lf.join(\n",
    "        keys, left_on=\"Wat is uw e-mailadres dat u opgaf voor SEMA3?\", right_on=\"Email\"\n",
    "    )\n",
    "    .rename(\n",
    "        {\n",
    "            \"Wat is uw e-mailadres dat u opgaf voor SEMA3?\": \"EMAIL\",\n",
    "            \"Id\": \"PARTICIPANT_ID\",\n",
    "        }\n",
    "    )\n",
    "    .drop([\"EMAIL\"])\n",
    ")\n",
    "\n",
    "demographics_lf = (\n",
    "    demographics_lf.join(keys, left_on=\"Wat is uw e-mailadres?\", right_on=\"Email\")\n",
    "    .rename(\n",
    "        {\n",
    "            \"Wat is uw e-mailadres?\": \"EMAIL\",\n",
    "            \"Id\": \"PARTICIPANT_ID\",\n",
    "        }\n",
    "    )\n",
    "    .drop([\"EMAIL\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sema_participants: list[str] = (\n",
    "    sema_lf.select(\"PARTICIPANT_ID\")\n",
    "    .unique()\n",
    "    .collect()\n",
    "    .to_dict(as_series=False)[\"PARTICIPANT_ID\"]\n",
    ")\n",
    "\n",
    "valid_final_survey_participants: list[str] = (\n",
    "    final_survey_lf.select(\"PARTICIPANT_ID\")\n",
    "    .unique()\n",
    "    .collect()\n",
    "    .to_dict(as_series=False)[\"PARTICIPANT_ID\"]\n",
    ")\n",
    "\n",
    "valid_participants = set.intersection(\n",
    "    set(valid_obse_participants),\n",
    "    set(valid_sema_participants + valid_final_survey_participants),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "obse_lf = (\n",
    "    obse_lf.filter(pl.col(\"PARTICIPANT_ID\").is_in(valid_participants))\n",
    "    .with_columns(\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"1\")\n",
    "                + pl.col(\"2\")\n",
    "                + pl.col(\"3\")\n",
    "                + pl.col(\"4\")\n",
    "                + pl.col(\"5\")\n",
    "                + pl.col(\"6\")\n",
    "                + pl.col(\"7\")\n",
    "                + pl.col(\"8\")\n",
    "                + pl.col(\"9\")\n",
    "                + pl.col(\"10\")\n",
    "            )\n",
    "            / 10\n",
    "        ).alias(\"MEAN\")\n",
    "    )\n",
    "    .sort(\"UPLOADED_TS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import DivisionByZero\n",
    "import math\n",
    "from typing import Literal, Union\n",
    "import statistics\n",
    "\n",
    "\n",
    "def maximum_variance(dataset: list[Union[int, float]]) -> float | Literal[0]:\n",
    "    mean: float = statistics.mean(dataset)\n",
    "    __min: int | float = min(dataset)\n",
    "    __max: int | float = max(dataset)\n",
    "    n: int = len(dataset)\n",
    "    if mean == __min or mean == __max:\n",
    "        return 0\n",
    "    else:\n",
    "        if abs(__min) > abs(__max):\n",
    "            tmp: int | float = __max\n",
    "            __max: int | float = __min\n",
    "            __min: int | float = tmp\n",
    "        n_max: int = math.floor((n * mean - n * __min) / (__max - __min))\n",
    "        n_min: int = n - 1 - n_max\n",
    "        if n_max == 0:\n",
    "            __max = 0\n",
    "        m: float = n * mean - n_min * __min - n_max * __max\n",
    "        return (\n",
    "            n_min * (__min - mean) ** 2 + n_max * (__max - mean) ** 2 + (mean - m) ** 2\n",
    "        ) / (n - 1)\n",
    "\n",
    "\n",
    "def relative_variance(dataset: list[Union[int, float]]):\n",
    "    variance: float = statistics.variance(dataset)\n",
    "    max_variance: float | Literal[0] = maximum_variance(dataset)\n",
    "    if max_variance == 0:\n",
    "        raise DivisionByZero(\"Division by zero\")\n",
    "    else:\n",
    "        return variance / max_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "obse_participant_mean = obse_lf.group_by(\"PARTICIPANT_ID\").agg(\n",
    "    [\n",
    "        pl.col(\"MEAN\").mean(),\n",
    "        (\n",
    "            pl.col(\"MEAN\")\n",
    "            .map_elements(lambda x: relative_variance(x), pl.Float64)\n",
    "            .name.map(lambda x: \"RELATIVE_VARIANCE\")\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x19c0d03c770>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obse_participant_mean.collect().write_csv(f\"{out.as_posix()}/obse_participant_mean.csv\")\n",
    "obse_participant_mean.collect().write_excel(f\"{out.as_posix()}/obse_participant_mean.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sema_lf = sema_lf.filter(pl.col(\"PARTICIPANT_ID\").is_in(valid_participants))\n",
    "final_survey_lf = final_survey_lf.filter(pl.col(\"PARTICIPANT_ID\").is_in(valid_participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_variable(header):\n",
    "    lst: list[str] = [f\"_{i}\" for i in range(1, 6)]\n",
    "    res = False\n",
    "    for el in lst:\n",
    "        if header.endswith(el):\n",
    "            res = True\n",
    "            break\n",
    "    return res\n",
    "\n",
    "\n",
    "FINAL_SURVEY_IDENTIFIERS: list[str] = [\"PARTICIPANT_ID\", \"UPLOADED_TS\", \"COMPLETED_TS\"]\n",
    "FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS = []\n",
    "for label in sema_lf.columns:\n",
    "    if first_variable(label):\n",
    "        FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS.append(label)\n",
    "FINAL_SURVEY_SATISFACTION_WITH_LIFE_QUESTIONS: list[str] = [\n",
    "    \"IDEAAL\",\n",
    "    \"OMSTANDIGHEDEN\",\n",
    "    \"TEVREDEN\",\n",
    "    \"BELANGRIJKE_DINGEN\",\n",
    "    \"NIETS_VERANDEREN\",\n",
    "]\n",
    "FINAL_SURVEY_PRESTATIE_QUESTIONS: list[str] = []\n",
    "werktevredenheid_eerste_variabele_lf: pl.LazyFrame = (\n",
    "    sema_lf.select(FINAL_SURVEY_IDENTIFIERS + FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS)\n",
    "    .cast(\n",
    "        {\n",
    "            FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS[i]: pl.UInt8\n",
    "            for i in range(len(FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS))\n",
    "        }\n",
    "    )\n",
    "    .filter(pl.col(\"COMPLETED_TS\").is_not_null() & pl.col(\"UPLOADED_TS\").is_not_null())\n",
    ")\n",
    "werktevredenheid_tweede_variabele_lf: pl.LazyFrame = (\n",
    "    sema_lf.select(\n",
    "        FINAL_SURVEY_IDENTIFIERS + FINAL_SURVEY_SATISFACTION_WITH_LIFE_QUESTIONS\n",
    "    )\n",
    "    .filter(pl.col(\"COMPLETED_TS\").is_not_null() & pl.col(\"UPLOADED_TS\").is_not_null())\n",
    "    .cast(\n",
    "        {\n",
    "            FINAL_SURVEY_SATISFACTION_WITH_LIFE_QUESTIONS[i]: pl.UInt8\n",
    "            for i in range(len(FINAL_SURVEY_SATISFACTION_WITH_LIFE_QUESTIONS))\n",
    "        }\n",
    "    )\n",
    ")\n",
    "DERDE_VARIABELEN_TO_DROP_COLUMNS = (\n",
    "    FINAL_SURVEY_SATISFACTION_WITH_LIFE_QUESTIONS\n",
    "    + FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS\n",
    "    + [str(i) for i in range(1, 11)]\n",
    ")\n",
    "for label in sema_lf.columns:\n",
    "    if (\n",
    "        label.endswith(\"_0\")\n",
    "        or label == \"SURVEY_NAME\"\n",
    "        or \"INLEIDING\" in label\n",
    "        or \"CLONE\" in label\n",
    "        or \")\" in label\n",
    "        or label == \"D\"\n",
    "        or label == \"ACTIVITEIT\"\n",
    "        or label == \"BEDANKT\"\n",
    "        or label == \"SLOT\"\n",
    "        or label == \"INTRO\"\n",
    "        or label == \"CONTROLLEVRAAG\"\n",
    "        or label == \"TAAKPRESTATIE\"\n",
    "    ):\n",
    "        DERDE_VARIABELEN_TO_DROP_COLUMNS.append(label)\n",
    "werktevredenheid_derde_variabele_lf = sema_lf.drop(\n",
    "    DERDE_VARIABELEN_TO_DROP_COLUMNS\n",
    ").filter(pl.col(\"COMPLETED_TS\").is_not_null() & pl.col(\"UPLOADED_TS\").is_not_null())\n",
    "werktevredenheid_headers = werktevredenheid_derde_variabele_lf.columns[3:]\n",
    "werktevredenheid_derde_variabele_lf = werktevredenheid_derde_variabele_lf.cast(\n",
    "    {\n",
    "        werktevredenheid_headers[i]: pl.UInt8\n",
    "        for i in range(len(werktevredenheid_headers))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted sum\n",
    "def compute_weighted_sum(lf):\n",
    "    cols = []\n",
    "    for i in FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS:\n",
    "        string = i.split(\"_\")[0]\n",
    "        if string not in cols:\n",
    "            cols.append(string)\n",
    "    for i in cols:\n",
    "        lf = lf.with_columns(\n",
    "            (\n",
    "                pl.col(f\"{i}_1\")\n",
    "                + pl.col(f\"{i}_2\") * 2\n",
    "                + pl.col(f\"{i}_3\") * 3\n",
    "                + pl.col(f\"{i}_4\") * 4\n",
    "                + pl.col(f\"{i}_5\") * 5\n",
    "            ).alias(i)\n",
    "        )\n",
    "    return lf\n",
    "\n",
    "\n",
    "werktevredenheid_eerste_variabele_lf = compute_weighted_sum(\n",
    "    werktevredenheid_eerste_variabele_lf\n",
    ").drop(FINAL_SURVEY_WERKTEVREDENHEID_QUESTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(lf, from_index):\n",
    "    mean_expr = pl.col(lf.columns[from_index])\n",
    "    for column in lf.columns[from_index + 1 :]:\n",
    "        mean_expr += pl.col(column)\n",
    "    mean_expr /= len(lf.columns[from_index:])\n",
    "    return lf.with_columns(mean_expr.alias(\"MEAN\"))\n",
    "\n",
    "\n",
    "werktevredenheid_eerste_variabele_lf = compute_mean(\n",
    "    werktevredenheid_eerste_variabele_lf, 3\n",
    ")\n",
    "werktevredenheid_tweede_variabele_lf = compute_mean(\n",
    "    werktevredenheid_tweede_variabele_lf, 3\n",
    ")\n",
    "\n",
    "werktevredenheid_derde_variabele_lf = compute_mean(\n",
    "    werktevredenheid_derde_variabele_lf, 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-30St-BHy-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
